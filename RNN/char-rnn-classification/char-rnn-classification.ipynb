{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 使用 RNN 网络对姓名进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 准备数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import unicodedata\n",
    "import string"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "#姓氏中所有的字符\n",
    "#string.ascii_letters是大小写各26字母\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "#字符的种类数\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "\n",
    "# 将Unicode码转换成标准的ASCII码\n",
    "def unicode_to_ascii(s):\n",
    "    '''\n",
    "\n",
    "    :param s: unicode_to_ascill编码的字符串\n",
    "    :param all_letters: 大小写各26字母 + \" .,;'\"\n",
    "    :return:\n",
    "    '''\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "print(n_letters) #字符数为57个\n",
    "print(unicode_to_ascii('Ślusàrski'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. 构建类别-姓名字典"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "\n",
    "data_path = Path('../../data/names')\n",
    "files = list(data_path.glob('*.txt')) # 列出所有txt文件"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "category_names = {} # dict 类别：姓名\n",
    "categorys = []\n",
    "\n",
    "def read_names(file):\n",
    "    names = open(file).read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(name) for name in names]\n",
    "\n",
    "for file in files:\n",
    "    names = read_names(file)\n",
    "    file_name = file.name[:-4]\n",
    "    categorys.append(file_name)\n",
    "    category_names[file_name] = names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "['Ang', 'AuYong', 'Bai', 'Ban', 'Bao']"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_names['Chinese'][:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. 将姓名转为tensor向量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "name = 'abdel'\n",
    "name = [[all_letters.find(char)] for char in name]\n",
    "name = torch.tensor(name, dtype=torch.int64)\n",
    "name = F.one_hot(name, num_classes=n_letters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "def name_to_oneHot(name):\n",
    "    name = [[all_letters.find(char)] for char in name]\n",
    "    name = torch.tensor(name, dtype=torch.int64)\n",
    "    name = F.one_hot(name, num_classes=n_letters)\n",
    "    return name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([6, 1, 57])"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'Khoury'\n",
    "name_tensor = name_to_oneHot(name)\n",
    "name_tensor.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. 构建数据生成器（用函数简单实现）"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "category = random.choice(categorys) # 随机选一个分类\n",
    "name = random.choice(category_names[category]) # 从随机分类中随机选一个名字\n",
    "name_tensor = name_to_oneHot(name)\n",
    "category_tensor = torch.tensor([categorys.index(category)], dtype=torch.long) # 类别标签"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "# 训练集，验证集，测试集比例\n",
    "train_rate = 0.8\n",
    "val_rate = 0.1\n",
    "test_rate = 0.1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "def get_data_set(type):\n",
    "    '''\n",
    "    按type选取训练集，验证集，测试集\n",
    "    :param type: str: train, val, test\n",
    "    :return:\n",
    "    '''\n",
    "    category = random.choice(categorys) # 随机选一个分类\n",
    "    # 选择 训练集，验证集，测试集\n",
    "    if type == 'train':\n",
    "        names = category_names[category]\n",
    "        name_len = len(names)\n",
    "        names = names[:int(name_len * train_rate)]\n",
    "    elif type == 'val':\n",
    "        names = category_names[category]\n",
    "        name_len = len(names)\n",
    "        names = names[int(name_len * train_rate): int(name_len * (train_rate + val_rate))]\n",
    "    elif type == 'test':\n",
    "        names = category_names[category]\n",
    "        name_len = len(names)\n",
    "        names = names[int(name_len * (train_rate + val_rate)):]\n",
    "    return (category, names)\n",
    "\n",
    "def data_generator(category, names):\n",
    "    '''\n",
    "    生成训练数据\n",
    "    :param category: str 分类\n",
    "    :param names: list 数据集\n",
    "    :return:\n",
    "    '''\n",
    "    indexs = list(range(len(names))) # 打乱下标，不直接修改names\n",
    "    random.shuffle(indexs)\n",
    "    for index in indexs:\n",
    "        name = names[index] # 从随机分类中随机选一个名字\n",
    "        name_tensor = name_to_oneHot(name)\n",
    "        category_tensor = torch.tensor([categorys.index(category)], dtype=torch.long) # 类别标签\n",
    "        yield (name_tensor, category_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "type = 'train'\n",
    "(category, names) = get_data_set(type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]) tensor([9])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for X, Y in  data_generator(category, names):\n",
    "    print(X, Y)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 构建模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. 定义网络"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "\n",
    "        # self.softMax = nn.Softmax()\n",
    "\n",
    "    # def forward(self, input, hidden):\n",
    "    #     # 每次只有一个单词，故而batch_size=1\n",
    "    #     # input: tensor (batch_size=1, input_size)\n",
    "    #     # hidden: tensor (batch_size=1, hidden_size)\n",
    "    #     combined = torch.cat((input, hidden), dim=1) # tensor (batch_size=1, input_size + hidden_size)\n",
    "    #     output = self.i2o(combined) # (batch_size=1, output_size)\n",
    "    #     hidden = self.i2h(combined) # (batch_size=1, hidden_size)\n",
    "    #     return output, hidden\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # 每次只有一个单词，故而batch_size=1\n",
    "        # input: tensor (time_step, batch_size=1, input_size)\n",
    "        # hidden: tensor (batch_size=1, hidden_size)\n",
    "        for step in range(input.size()[0]):\n",
    "            combined = torch.cat((input[step], hidden), dim=1) # tensor (batch_size=1, input_size + hidden_size)\n",
    "            output = self.i2o(combined) # (batch_size=1, output_size)\n",
    "            hidden = self.i2h(combined) # (batch_size=1, hidden_size)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        '''\n",
    "        初始化隐藏层参数\n",
    "        :return:\n",
    "        '''\n",
    "        return torch.zeros((1, self.hidden_size)) # (batch_size=1, hidden_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "input_size = 57\n",
    "hidden_size = 256\n",
    "output_size = 18\n",
    "\n",
    "rnn = RNN(input_size,\n",
    "          hidden_size,\n",
    "          output_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "type = 'train'\n",
    "(category, names) = get_data_set(type)\n",
    "x, y = next(data_generator(category, names))\n",
    "hidden = rnn.init_hidden()\n",
    "output, hidden = rnn(x, hidden)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. 定义参数\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "INPUT_SIZE = n_letters # 字母总数\n",
    "HIDDEN_SIZE = 256\n",
    "OUTPUT_SIZE = len(categorys) # 类别数\n",
    "EPOCHS = 200\n",
    "\n",
    "lr = 1e-3\n",
    "val_period = 5 # 每50个epoch打印一次\n",
    "predict_period = 10 # 每\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 交叉熵\n",
    "optim = torch.optim.Adam(rnn.parameters(), lr=lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. 训练与验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    '''\n",
    "    训练模型\n",
    "    :param model:\n",
    "    :return:\n",
    "    '''\n",
    "    type = 'train'\n",
    "    (category, names) = get_data_set(type)\n",
    "    l_sum = 0\n",
    "    num = 0\n",
    "    for x, y in data_generator(category, names):\n",
    "        num += 1\n",
    "        hidden = model.init_hidden()\n",
    "        output, hidden = model(x, hidden)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        l_sum += loss.item()\n",
    "    return output, l_sum / num"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "def cal_accuracy(model, data_gen):\n",
    "    '''\n",
    "    计算误差\n",
    "    :param model: 模型\n",
    "    :param data_gen: 数据生成器\n",
    "    :return:\n",
    "    '''\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    num = 0\n",
    "    for x, y in data_gen:\n",
    "        hidden = model.init_hidden()\n",
    "        output, _ = model(x, hidden)\n",
    "        label = output.argmax(dim=1).item()\n",
    "        if label == y.item():\n",
    "            acc += 1\n",
    "        num += 1\n",
    "    model.train()\n",
    "    return acc / num"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "def predict(model, name, n_predictons=3):\n",
    "    '''\n",
    "    给定姓名进行预测\n",
    "    :param model:\n",
    "    :param name: str 姓名\n",
    "    :param n_predictons: int top-K个类别\n",
    "    :return: list->tuple [(name, value)]\n",
    "    '''\n",
    "    hidden = model.init_hidden()\n",
    "    name_tensor = name_to_oneHot(name)\n",
    "    output, _ = model(name_tensor, hidden)\n",
    "\n",
    "    # topv: 下标 tensor (1, n_predictons)\n",
    "    # topi: 值 tensor (1, n_predictons)\n",
    "    topv, topi = output.data.topk(n_predictons, 1, True) # 取概率最大的前几个\n",
    "\n",
    "    prediction = [(categorys[topi[0][index].item()], topv[0][index].item()) for index in range(n_predictons)]\n",
    "    return prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [00:28<06:55,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8971176403705203\n",
      "2.7833542346954347\n",
      "2.885395543768822\n",
      "2.9008847932775312\n",
      "2.903180030287889\n",
      "7 8\n",
      "7 8\n",
      "11 8\n",
      "7 8\n",
      "11 8\n",
      "11 8\n",
      "1 8\n",
      "11 8\n",
      "11 8\n",
      "7 8\n",
      "11 8\n",
      "11 8\n",
      "7 8\n",
      "7 8\n",
      "11 8\n",
      "11 8\n",
      "11 8\n",
      "11 8\n",
      "8 8\n",
      "11 8\n",
      "11 8\n",
      "7 8\n",
      "11 8\n",
      "epoch 4, acc 0.043478, time 2.19 sec, Fearghal(Irish) -> Korean(0.070816)\n",
      "2.903180030287889\n",
      "2.885395543768822\n",
      "2.9060204600856316\n",
      "2.9008847932775312\n",
      "2.8950609873081077\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "2 2\n",
      "2 2\n",
      "7 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "12 2\n",
      "11 2\n",
      "15 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "17 2\n",
      "11 2\n",
      "11 2\n",
      "7 2\n",
      "7 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "7 2\n",
      "11 2\n",
      "7 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "11 2\n",
      "epoch 9, acc 0.038462, time 0.28 sec, Akrivopoulos(Greek) -> Korean(0.168224)\n",
      "2.903180030287889\n",
      "2.9008847932775312\n",
      "2.885395543768822\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-154-2799a3e2101c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mEPOCHS\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[0mstart\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m     \u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrnn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[0mloss_all\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-146-6ee0d505d5ef>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(model)\u001B[0m\n\u001B[0;32m     17\u001B[0m         \u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m         \u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m         \u001B[0ml_sum\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ml_sum\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mnum\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\learn\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 26\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     27\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mF\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\learn\\lib\\site-packages\\torch\\optim\\adam.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    106\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    107\u001B[0m             \u001B[0mbeta1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbeta2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgroup\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'betas'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 108\u001B[1;33m             F.adam(params_with_grad,\n\u001B[0m\u001B[0;32m    109\u001B[0m                    \u001B[0mgrads\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m                    \u001B[0mexp_avgs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\learn\\lib\\site-packages\\torch\\optim\\functional.py\u001B[0m in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001B[0m\n\u001B[0;32m     85\u001B[0m         \u001B[1;31m# Decay the first and second moment running average coefficient\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m         \u001B[0mexp_avg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmul_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbeta1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mbeta1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 87\u001B[1;33m         \u001B[0mexp_avg_sq\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmul_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbeta2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maddcmul_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mbeta2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     88\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mamsgrad\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     89\u001B[0m             \u001B[1;31m# Maintains the maximum of all 2nd moment running avg. till now\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "rnn = RNN(INPUT_SIZE,\n",
    "          HIDDEN_SIZE,\n",
    "          OUTPUT_SIZE)\n",
    "\n",
    "loss_all = []\n",
    "\n",
    "\n",
    "\n",
    "# test_gen = data_generator(*get_data_set('test'))\n",
    "\n",
    "rnn.train()\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    start = time.time()\n",
    "    output, loss = train(rnn)\n",
    "    print(loss)\n",
    "    loss_all.append(loss)\n",
    "\n",
    "    if (epoch + 1) % val_period == 0:\n",
    "        val_gen = data_generator(*get_data_set('val'))\n",
    "        acc = cal_accuracy(rnn, val_gen)\n",
    "        category = random.choice(categorys) # 在测试集中选一个名字，进行预测\n",
    "        name = random.choice(category_names[category])\n",
    "        predictions = predict(rnn, name)[0]\n",
    "        print('epoch %d, acc %f, time %.2f sec, %s(%s) -> %s(%f)'\n",
    "              %(epoch, acc, time.time() - start, name, category, predictions[0], predictions[1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}